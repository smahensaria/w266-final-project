{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exploration_FineTune_GPT-2M-GenText3.ipynb","provenance":[{"file_id":"1l8rqAB4KMzAIDhqRN_DzHaxukDsEhrTX","timestamp":1626518913879}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BpeoW7kBrFz3"},"source":["## Notebook Preface"]},{"cell_type":"markdown","metadata":{"id":"E7C3qzmA84B_"},"source":["## Constructs the working folder\n","\n","* Positions the project folder in the Google Drive.\n","  1. From \"Share with me\", right click on \"W266 Final Project\", select \"Add shortcut to Drive\"\n","  2. \"W266 Final Project\" will show up in \"MyDrive\"\n","\n","* Mounts the Google Drive at /content/drive in the Colab runtime.\n","\n","* Defines the working folder relative to /content/drive.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"XHIiXFTy4GRo","executionInfo":{"status":"ok","timestamp":1627399590475,"user_tz":420,"elapsed":340,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"defd2767-7799-42eb-c57d-2486cec83ce4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ubXvrhww4ZRt","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1627399590818,"user_tz":420,"elapsed":18,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"3b3c076e-1cb9-4155-bcf6-e8c410a94c57"},"source":["working_folder = \"/content/drive/MyDrive/W266 Final Project/CnF/PhotoStoryGenerator\"\n","checkpoint_dir = f\"{working_folder}/GPT-2M-FineTune3_checkpoint\"\n","testing_json = f\"{working_folder}/test_hints.json\"\n"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Qi7gcmhD_TQW","colab":{"base_uri":"https://localhost:8080/","height":361},"executionInfo":{"status":"ok","timestamp":1627399591349,"user_tz":420,"elapsed":547,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"a771bb6d-06b5-4973-ea5b-30446660b463"},"source":["!nvidia-smi\n"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Tue Jul 27 15:26:30 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    36W / 250W |   4997MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W9eBLhOk8-eH"},"source":["## Imports libraries"]},{"cell_type":"code","metadata":{"id":"_Rb1BSLugcZn","colab":{"base_uri":"https://localhost:8080/","height":413},"executionInfo":{"status":"ok","timestamp":1627399593672,"user_tz":420,"elapsed":2332,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"8eebd70f-3369-483e-a168-6e4023850562"},"source":["# First upload the training and evaluation files to this runtime (Press connect if needed)\n","!pip install transformers torch\n"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ltEwIIMDg9ex","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1627399593674,"user_tz":420,"elapsed":16,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"913b12e4-e455-4d9b-8b47-4791f83cdfbe"},"source":["import json\n","import logging\n","import math\n","import os\n","import re\n","from dataclasses import dataclass, field\n","from typing import Optional\n","\n","import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","from transformers import (\n","    AutoConfig,\n","    GPT2LMHeadModel,\n","    AutoTokenizer,\n","    TextGenerationPipeline,\n","    pipeline,\n","    set_seed,\n",")\n","\n","# Setup logging\n","logger = logging.getLogger(__name__)\n","\n","from IPython.display import HTML, display\n","def set_css():\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","get_ipython().events.register('pre_run_cell', set_css)\n"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":913},"id":"bCibZqKdhO9j","executionInfo":{"status":"ok","timestamp":1627399628867,"user_tz":420,"elapsed":35207,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"a89b8baa-589a-4387-bcc6-e1a589986b04"},"source":["#METEOR\n","!pip install nltk==3.5\n","import nltk\n","nltk.download('wordnet')\n","\n","#BLEU\n","from nltk.translate.bleu_score import sentence_bleu\n","\n","#ROUGE\n","!pip install rouge-score\n","from rouge_score import rouge_scorer\n","Rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n","\n","#BERT SCORE\n","!pip install bert_score\n","from bert_score import BERTScorer\n","BERT_scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n"],"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Requirement already satisfied: nltk==3.5 in /usr/local/lib/python3.7/dist-packages (3.5)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.5) (1.0.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.5) (4.41.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk==3.5) (2019.12.20)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.5) (7.1.2)\n"],"name":"stdout"},{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stderr"},{"output_type":"stream","text":["Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score) (3.5)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (0.12.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.19.5)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->rouge-score) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->rouge-score) (7.1.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk->rouge-score) (2019.12.20)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->rouge-score) (4.41.1)\n","Requirement already satisfied: bert_score in /usr/local/lib/python3.7/dist-packages (0.3.9)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from bert_score) (1.1.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert_score) (3.2.2)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from bert_score) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bert_score) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert_score) (2.23.0)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bert_score) (1.9.0+cu102)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from bert_score) (4.9.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert_score) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->bert_score) (3.7.4.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->bert_score) (21.0)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->bert_score) (0.0.12)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->bert_score) (4.6.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->bert_score) (0.10.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->bert_score) (2019.12.20)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->bert_score) (5.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->bert_score) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->bert_score) (0.0.45)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=3.0.0->bert_score) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0->bert_score) (3.5.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score) (1.3.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->bert_score) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->bert_score) (1.0.1)\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"GEyZCqQthYon"},"source":["## Defines score computer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"5LCOWC_cvXGo","executionInfo":{"status":"ok","timestamp":1627399628868,"user_tz":420,"elapsed":34,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"c29b6f87-0177-47fd-84c0-cc5df6659684"},"source":["def get_scores(reference, hypothesis):\n","    rouge = Rouge_scorer.score(reference, hypothesis)\n","    P, R, F1 = BERT_scorer.score([hypothesis], [reference])\n","\n","    return {\n","        \"meteor\": nltk.translate.meteor_score.meteor_score([reference], hypothesis),\n","        \"rouge1\": { \"precision\": rouge[\"rouge1\"].precision, \"recall\": rouge[\"rouge1\"].recall, \"fmeasure\": rouge[\"rouge1\"].fmeasure },\n","        \"rougeL\": { \"precision\": rouge[\"rougeL\"].precision, \"recall\": rouge[\"rougeL\"].recall, \"fmeasure\": rouge[\"rougeL\"].fmeasure },\n","        \"bleu\": sentence_bleu([reference.split()], hypothesis.split(), weights=(1, 0, 0, 0)),\n","        \"bert_score\": { \"precision\": P.item(), \"recall\": R.item(), \"f1\": F1.item() }\n","    }\n"],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"a-CMf51yfbTG"},"source":["## Constructs the testing dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"dlQqyFM7ffZz","executionInfo":{"status":"ok","timestamp":1627399628869,"user_tz":420,"elapsed":31,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"ad762313-3e3b-48fd-c4b4-f64a9a6af965"},"source":["def load_dataset_for_testing(num_records):\n","    results = []\n","    with open (testing_json) as f:\n","        _json = json.load(f)\n","        for s in _json:\n","           story = _json[s]\n","           hints = story[\"hints\"]\n","           results.append({\n","               \"story_id\": s,\n","               \"reference\": story[\"sis\"],\n","               \"base_prefix\": \" \".join(hints[1]),\n","               \"prefix\": f\"<BOS> <HINT> {' '.join(hints[3])} <SENT>\",\n","               \"urls\": story[\"urls\"]\n","           })\n","           num_records -= 1\n","           if num_records <= 0:\n","              break\n","        return results\n"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"pqFqC_pJiNvj"},"source":["## Creates the story generation pipeline"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"jgRRjX0YmsXI","executionInfo":{"status":"ok","timestamp":1627399651754,"user_tz":420,"elapsed":22914,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"59bd1427-4ea3-4b24-cbe4-c6a1a699058f"},"source":["@dataclass\n","class TextGenerationArguments:\n","    _num_tests: int = 100\n","    _output: str = None\n","    _prefix: str = \"prefix\"\n","    _parsing_regex: re = None\n","    max_length: int = 500\n","    num_return_sequences: Optional[int] = None\n","    early_stopping: bool = False\n","\n","    # Sampling\n","    do_sample: Optional[bool] = None\n","\n","    # Redistribute the probability for the top K words\n","    # Limit the sampling pool\n","    # Lmiting the sample pool to a fixed size K could endanger the model to\n","    #   produce gibberish for sharp distributions and\n","    #   limit the model's creativity for flat distribution.\n","    # Default: 50\n","    top_k: Optional[int] = None\n","\n","    # Dynamically set the size of the sampling pool\n","    #   with the probability of the selected words summed up to p%\n","    # Default: 1.0\n","    top_p: Optional[float] = None\n","\n","    # The lower the temperature\n","    # 1. The more deterministic the output\n","    # 2. Word of higher probability is chosen\n","    # 3. Lower temperature to fix gibberish\n","    # 4. 0: most deterministic, probably more repetition\n","    # Default: 1.0\n","    temperature: Optional[float] = None\n","\n","    # 1: No penalty\n","    # Infinity: Max penalty\n","    repetition_penalty: Optional[float] = None\n","\n","    # Beam Search\n","    num_beams: Optional[int] = None\n","    no_repeat_ngram_size: Optional[int] = None\n","\n","\n","@dataclass\n","class ModelArguments:\n","    model_name_or_path: Optional[str] = None\n","    cache_dir: Optional[str] = None\n","    model_type: Optional[str] = None\n","\n","\n","model = GPT2LMHeadModel.from_pretrained(checkpoint_dir)\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint_dir)\n","story_generator = TextGenerationPipeline(model=model, tokenizer=tokenizer, device=0)\n"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"WlG4vLYCuNCk","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1627399651774,"user_tz":420,"elapsed":33,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"2a379044-580a-46cb-a306-e01cbeb8bdf3"},"source":["def dump_data(_data, _file):\n","    with open(f\"{_file}\", \"w\") as outfile:\n","        json.dump(_data, outfile)\n"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"5yt4ZFc8mJGM"},"source":["## Text generation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"PjD5qwqpIXQm","executionInfo":{"status":"ok","timestamp":1627399651776,"user_tz":420,"elapsed":31,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"ec784298-e026-48fe-9bde-c8639da9d235"},"source":["#story_regex = re.compile(\"^<BOS> <HINT> [^<>]+ <SENT> (?P<SENT>[^.!?]+[.!?][^.!?]+[.!?][^.!?]+[.!?][^.!?]+[.!?][^.!?]+[.!?]).+\", re.MULTILINE|re.IGNORECASE)\n","story_regex = re.compile(\"^(?P<SENT>[^.!?]+[.!?][^.!?]+[.!?][^.!?]+[.!?][^.!?]+[.!?][^.!?]+[.!?]).+\", re.MULTILINE|re.IGNORECASE)\n","\n","configs = [\n","    TextGenerationArguments(\n","        _num_tests = 100,\n","        _output = \"FT_BS_B1\",\n","        _prefix = \"prefix\",\n","        _parsing_regex = story_regex,\n","        max_length = 500,\n","        num_beams = 1,\n","        no_repeat_ngram_size = 3,\n","        num_return_sequences = 1,\n","        repetition_penalty = 1.1,\n","    ),\n","    TextGenerationArguments(\n","        _num_tests = 100,\n","        _output = \"FT_BS_B3\",\n","        _prefix = \"prefix\",\n","        _parsing_regex = story_regex,\n","        max_length = 500,\n","        num_beams = 3,\n","        no_repeat_ngram_size = 3,\n","        num_return_sequences = 3,\n","        repetition_penalty = 1.1,\n","    ),\n","    TextGenerationArguments(\n","        _num_tests = 100,\n","        _output = \"FT_BS_B5\",\n","        _prefix = \"prefix\",\n","        _parsing_regex = story_regex,\n","        max_length = 500,\n","        num_beams = 5,\n","        no_repeat_ngram_size = 3,\n","        num_return_sequences = 5,\n","        repetition_penalty = 1.1,\n","    ),\n","    TextGenerationArguments(\n","        _num_tests = 100,\n","        _output = \"FT_BS_B10\",\n","        _prefix = \"prefix\",\n","        _parsing_regex = story_regex,\n","        max_length = 500,\n","        num_beams = 10,\n","        no_repeat_ngram_size = 3,\n","        num_return_sequences = 10,\n","        repetition_penalty = 1.1,\n","    ),\n","    TextGenerationArguments(\n","        _num_tests = 100,\n","        _output = \"FT_KP_K50\",\n","        _prefix = \"prefix\",\n","        _parsing_regex = story_regex,\n","        max_length = 500,\n","        do_sample = True,\n","        top_k = 50,\n","        top_p = 1,\n","        repetition_penalty = 1.1,\n","    ),\n","    TextGenerationArguments(\n","        _num_tests = 100,\n","        _output = \"FT_KP_P8\",\n","        _prefix = \"prefix\",\n","        _parsing_regex = story_regex,\n","        max_length = 500,\n","        do_sample = True,\n","        top_k = 0,\n","        top_p = 0.80,\n","        repetition_penalty = 1.1,\n","    ),\n","    TextGenerationArguments(\n","        _num_tests = 100,\n","        _output = \"FT_KP_P9\",\n","        _prefix = \"prefix\",\n","        _parsing_regex = story_regex,\n","        max_length = 500,\n","        do_sample = True,\n","        top_k = 0,\n","        top_p = 0.90,\n","        temperature = 0.7,\n","        repetition_penalty = 1.1,\n","    ),\n","    TextGenerationArguments(\n","        _num_tests = 100,\n","        _output = \"FT_KP_P95\",\n","        _prefix = \"prefix\",\n","        _parsing_regex = story_regex,\n","        max_length = 500,\n","        do_sample = True,\n","        top_k = 0,\n","        top_p = 0.95,\n","        temperature = 0.7,\n","        repetition_penalty = 1.1,\n","    ),\n","]\n","\n"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"dEDod1X24Bsu","executionInfo":{"status":"ok","timestamp":1627399651777,"user_tz":420,"elapsed":29,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"35ea072d-629d-466d-d13f-d5c2e285c9c5"},"source":["#story_regex = re.compile(\"^<BOS> <HINT> [^<>]+ <SENT> (?P<SENT>[^.!?]+[.!?][^.!?]+[.!?][^.!?]+[.!?][^.!?]+[.!?][^.!?]+[.!?]).+\", re.MULTILINE|re.IGNORECASE)\n","story_regex = re.compile(\"^(?P<SENT>[^.!?]+[.!?][^.!?]+[.!?][^.!?]+[.!?][^.!?]+[.!?][^.!?]+[.!?]).+\", re.MULTILINE|re.IGNORECASE)\n","\n","configs = [\n","    TextGenerationArguments(\n","        _num_tests = 100,\n","        _output = \"FTM3_BS_B5\",\n","        _prefix = \"prefix\",\n","        _parsing_regex = story_regex,\n","        max_length = 500,\n","        num_beams = 5,\n","        no_repeat_ngram_size = 3,\n","        num_return_sequences = 1,\n","        repetition_penalty = 1.1,\n","    ),\n","    TextGenerationArguments(\n","        _num_tests = 100,\n","        _output = \"FTM3_KP_P95\",\n","        _prefix = \"prefix\",\n","        _parsing_regex = story_regex,\n","        max_length = 500,\n","        do_sample = True,\n","        top_k = 0,\n","        top_p = 0.95,\n","        temperature = 0.7,\n","        repetition_penalty = 1.1,\n","    ),\n","]"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"nODT_hchmLdH","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1627401364802,"user_tz":420,"elapsed":1713052,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"0fac18da-2bbc-4b14-a57f-f35e35a6d8fb"},"source":["#https://huggingface.co/blog/how-to-generate\n","\n","for config in configs:\n","    data = load_dataset_for_testing(config._num_tests)\n","    print(\"Configuration:\", config._output)\n","\n","    set_seed(0)\n","    for d in data:\n","        stories = story_generator(d[config._prefix], **(config.__dict__))\n","\n","        best = {\"text\": \"\", \"scores\": {\n","            \"meteor\": -100,\n","            \"rouge1\": { \"precision\": -100, \"recall\": -100, \"fmeasure\": -100 },\n","            \"rougeL\": { \"precision\": -100, \"recall\": -100, \"fmeasure\": -100 },\n","            \"bleu\": -100,\n","            \"bert_score\": { \"precision\": -100, \"recall\": -100, \"f1\": -100 },\n","        }}\n","\n","        for story in stories:\n","            gen_text = story[\"generated_text\"].replace(\"\\n\", \"\")[len(d[config._prefix])+1:]\n","            match = story_regex.match(gen_text)\n","            if match is not None:\n","                hypothesis = match.group(\"SENT\")\n","            else:\n","                #hypothesis = gen_text[:len(d[config._prefix])]\n","                hypothesis = \" \".join(gen_text.split()[:75])\n","            if len(hypothesis) == 0:\n","                continue\n","            scores = get_scores(d[\"reference\"], hypothesis)\n","            if scores[\"meteor\"] > best[\"scores\"][\"meteor\"]:\n","                best = {\"text\": hypothesis, \"scores\": scores}\n","        d[config._output] = best\n","\n","    dump_data(data, f\"{working_folder}/{config._output}_results.json\")\n","    print(\"Save results:\", f\"{config._output}_results.json\")\n"],"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"],"name":"stderr"},{"output_type":"stream","text":["Configuration: FTM3_BS_B5\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:516: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:516: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:516: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"],"name":"stderr"},{"output_type":"stream","text":["Save results: FTM3_BS_B5_results.json\n","Configuration: FTM3_KP_P95\n"],"name":"stdout"},{"output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"],"name":"stderr"},{"output_type":"stream","text":["Save results: FTM3_KP_P95_results.json\n"],"name":"stdout"}]}]}