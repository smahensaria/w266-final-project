{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"GPT-2M-FineTune3.ipynb","provenance":[{"file_id":"1l8rqAB4KMzAIDhqRN_DzHaxukDsEhrTX","timestamp":1626518913879}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a837de954ca745d68b4711b44c1d55eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8a056db9ec134ae8a8d4d76b20220137","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cb8c48698f384431b5745948d106d76e","IPY_MODEL_9fd1d99781324138af0b7c96b1a2da9c"]}},"8a056db9ec134ae8a8d4d76b20220137":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cb8c48698f384431b5745948d106d76e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fbb7a0343f254f5d92a67e7e64939f6f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":718,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":718,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bcd1cee7f448481e9c095a15dbaba237"}},"9fd1d99781324138af0b7c96b1a2da9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_73f6a55522384c2f81e535405837124e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 718/718 [00:00&lt;00:00, 933B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5640b2aa60fc4daeb790bcf1998d31ab"}},"fbb7a0343f254f5d92a67e7e64939f6f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bcd1cee7f448481e9c095a15dbaba237":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"73f6a55522384c2f81e535405837124e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5640b2aa60fc4daeb790bcf1998d31ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cf1e9cfecd114e108498f8597dc9dce8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_551de46a771547048c691af99e79fcb6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_75cf429061164333b1fe83449d5d8e96","IPY_MODEL_6f645f614d66431ba3675fcce4d9f840"]}},"551de46a771547048c691af99e79fcb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75cf429061164333b1fe83449d5d8e96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_98347625b4244e9fb384c062c9d9849d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1520013706,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1520013706,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5765f42af09c47e79b3eb31b38722e94"}},"6f645f614d66431ba3675fcce4d9f840":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_53f5133c1a7146daa804849ba98548c4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.52G/1.52G [02:22&lt;00:00, 10.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dc4daf36d2e440928aa62565925e391f"}},"98347625b4244e9fb384c062c9d9849d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5765f42af09c47e79b3eb31b38722e94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"53f5133c1a7146daa804849ba98548c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dc4daf36d2e440928aa62565925e391f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"249c875948884376a33718de5c0e6edd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a0a4cb0ff534436bbb40243727be77ab","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1f216e975f574e7eb03059c46eb20f67","IPY_MODEL_5ab199eb99ae488e9edcc8d17dc97d6f"]}},"a0a4cb0ff534436bbb40243727be77ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1f216e975f574e7eb03059c46eb20f67":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ed06efaf35164f93baa14a388a10403f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1042301,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1042301,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_73027f6a8a9942c7ac77e8f32ebc0946"}},"5ab199eb99ae488e9edcc8d17dc97d6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_441db225c62a4ddcb6c0d8ebd4f83ee9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.04M/1.04M [00:02&lt;00:00, 447kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e4cb4eed883643a9965604fef1f0f8a9"}},"ed06efaf35164f93baa14a388a10403f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"73027f6a8a9942c7ac77e8f32ebc0946":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"441db225c62a4ddcb6c0d8ebd4f83ee9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e4cb4eed883643a9965604fef1f0f8a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fea1fd9bfb31430faa1242b385b7ee71":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_67ac31fb4cb94ca193d47b7bcb23fd91","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a26869b455a54a3b954bb0486fd76c6a","IPY_MODEL_315e9c8ad7bc49a087bf453e80e2cd02"]}},"67ac31fb4cb94ca193d47b7bcb23fd91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a26869b455a54a3b954bb0486fd76c6a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_53d4b908efff4d468399a66017fcbd02","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c8bdc2d32a814541a1a4671a1e1d7e5a"}},"315e9c8ad7bc49a087bf453e80e2cd02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cfca8bfe639d4698ac844b235eb8ff2e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:12&lt;00:00, 35.7kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d06e9feeec5d4965b5eb27744718e2e4"}},"53d4b908efff4d468399a66017fcbd02":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c8bdc2d32a814541a1a4671a1e1d7e5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cfca8bfe639d4698ac844b235eb8ff2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d06e9feeec5d4965b5eb27744718e2e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"08759b250e1749d1b2d318c90f4f373a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8b3faac218444ce1b7b984136bac1cc6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4d3be4a241fc48c792a2384237c08d1e","IPY_MODEL_745c609a35f347d188b7c516e78959b5"]}},"8b3faac218444ce1b7b984136bac1cc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4d3be4a241fc48c792a2384237c08d1e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4ba8fc9b18c448f7b81fe1cb4698b84d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355256,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355256,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4eef64ae2c884c89a947a2287ab7b365"}},"745c609a35f347d188b7c516e78959b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_81993161284544fa84771d9258d04a11","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:10&lt;00:00, 127kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_95ccc7e1409b46ec9cf301b5967f4da9"}},"4ba8fc9b18c448f7b81fe1cb4698b84d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4eef64ae2c884c89a947a2287ab7b365":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"81993161284544fa84771d9258d04a11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"95ccc7e1409b46ec9cf301b5967f4da9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"BpeoW7kBrFz3"},"source":["## Notebook Preface\n","\n"]},{"cell_type":"markdown","metadata":{"id":"E7C3qzmA84B_"},"source":["## Constructs the working folder\n","\n","* Positions the project folder in the Google Drive.\n","  1. From \"Share with me\", right click on \"W266 Final Project\", select \"Add shortcut to Drive\"\n","  2. \"W266 Final Project\" will show up in \"MyDrive\"\n","\n","* Mounts the Google Drive at /content/drive in the Colab runtime.\n","\n","* Defines the working folder relative to /content/drive.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XHIiXFTy4GRo","executionInfo":{"status":"ok","timestamp":1627389521279,"user_tz":420,"elapsed":21226,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"b744812a-6861-402c-b3d4-ce7d6de0941d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ubXvrhww4ZRt","executionInfo":{"status":"ok","timestamp":1627389523681,"user_tz":420,"elapsed":24,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}}},"source":["working_folder = \"/content/drive/MyDrive/W266 Final Project/CnF/PhotoStoryGenerator\"\n","training_json = f\"{working_folder}/train_hints.json\"\n","eval_json = f\"{working_folder}/val_hints.json\"\n","testing_json = f\"{working_folder}/test_hints.json\"\n","\n","training_text = f\"{working_folder}/train_input_M3.txt\"\n","eval_text = f\"{working_folder}/val_input_M3.txt\"\n","testing_text = f\"{working_folder}/test_input_M3.txt\"\n","\n","checkpoint_dir = f\"{working_folder}/GPT-2M-FineTune3_checkpoint\"\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qi7gcmhD_TQW","executionInfo":{"status":"ok","timestamp":1627389523683,"user_tz":420,"elapsed":24,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"092c40ca-90aa-44d4-a875-da088688c5b8"},"source":["!nvidia-smi\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Tue Jul 27 12:38:43 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W9eBLhOk8-eH"},"source":["## Imports libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Rb1BSLugcZn","executionInfo":{"status":"ok","timestamp":1627389531061,"user_tz":420,"elapsed":7393,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"dfa29f4a-edda-44a5-8e4c-f6f0b78c3544"},"source":["# First upload the training and evaluation files to this runtime (Press connect if needed)\n","!pip install transformers torch\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 3.8 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 32.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 66.6 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 71.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ltEwIIMDg9ex","executionInfo":{"status":"ok","timestamp":1627389535505,"user_tz":420,"elapsed":4451,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}}},"source":["import json\n","import logging\n","import math\n","import os\n","from dataclasses import dataclass, field\n","from typing import Optional\n","\n","from transformers import (\n","    CONFIG_MAPPING,\n","    MODEL_WITH_LM_HEAD_MAPPING,\n","    AutoConfig,\n","    GPT2LMHeadModel,\n","    AutoTokenizer,\n","    DataCollatorForLanguageModeling,\n","    LineByLineTextDataset,\n","    PreTrainedTokenizer,\n","    TextDataset,\n","    Trainer,\n","    TrainingArguments,\n","    set_seed,\n",")\n","\n","# Setup logging\n","logger = logging.getLogger(__name__)\n","\n","from IPython.display import HTML, display\n","def set_css():\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","get_ipython().events.register('pre_run_cell', set_css)\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HBcPrF6AxfbX"},"source":["## Converts the datasets to model inputs\n","\n","* Run only once to generate the input files."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"nQ1Yzb27xiW2","executionInfo":{"status":"ok","timestamp":1627389537131,"user_tz":420,"elapsed":14,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"10d11c80-d5b0-4c51-cb3b-fa35144c64d6"},"source":["def convert_dataset_to_input(_json, _data):\n","    with open (_json) as f:\n","        data = json.load(f)\n","    with open(_data, \"w+\") as fout:\n","        for s in data:\n","            story = data[s]\n","            # Use the first hint (nouns of dii)\n","            # The second hint is concatenation of dii\n","            hints = story[\"hints\"]\n","            fout.write(f\"<BOS> <HINT> {' '.join(hints[3])} <SENT> {story['sis']} <EOS>\\n\")\n","#            for hint in story[\"hints\"]:\n","#                fout.write(f\"<BOS> <HINT> {' '.join(hint)} <SENT> {story['sis']} <EOS>\\n\")\n"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"XBTLHT2fzssC","executionInfo":{"status":"ok","timestamp":1627389543826,"user_tz":420,"elapsed":6705,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"29b6d0bf-4f98-4b1d-b8a6-b6c86a732f5a"},"source":["convert_dataset_to_input(training_json, training_text)\n"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"pfjeIs3gzuG4","executionInfo":{"status":"ok","timestamp":1627389545513,"user_tz":420,"elapsed":1699,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"30ccdbeb-ec36-4e4e-f795-6433dbbe1151"},"source":["convert_dataset_to_input(eval_json, eval_text)\n"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"CIP-jqHVzu_C","executionInfo":{"status":"ok","timestamp":1627389547644,"user_tz":420,"elapsed":2142,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"bfa5369c-c3b0-4186-cd75-04384c48eca3"},"source":["convert_dataset_to_input(testing_json, testing_text)\n"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"wWohnthH9eRy"},"source":["# Defines model arguments and data processing functions"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"IL0YR9WMhG0v","executionInfo":{"status":"ok","timestamp":1627389547645,"user_tz":420,"elapsed":24,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"37930572-0679-403e-f675-3883f48ff463"},"source":["@dataclass\n","class ModelArguments:\n","    model_name_or_path: Optional[str] = None\n","    cache_dir: Optional[str] = None\n","    model_type: Optional[str] = None\n"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"fX9aWWf1hL4X","executionInfo":{"status":"ok","timestamp":1627389547646,"user_tz":420,"elapsed":21,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"3621845d-c381-4914-a2fa-e0561384ba53"},"source":["@dataclass\n","class DataArguments:\n","    train_data_file: Optional[str] = None\n","    eval_data_file: Optional[str] = None\n","    block_size: int = -1\n","    line_by_line: bool = False # Load the data line by line, trimmed/padded to block_size; otherwise, load sequentially by block_size\n","    mlm: bool = False # Train with masked language model loss\n","    overwrite_cache: bool = False\n"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"Od_Gxsz1hZvV","executionInfo":{"status":"ok","timestamp":1627389547646,"user_tz":420,"elapsed":19,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"f44180a3-1744-4c58-b329-8b8503453966"},"source":["def get_dataset(args: DataArguments, tokenizer: PreTrainedTokenizer, evaluate=False):\n","    file_path = args.eval_data_file if evaluate else args.train_data_file\n","\n","    if args.line_by_line:\n","        return LineByLineTextDataset(tokenizer=tokenizer, file_path=file_path, block_size=args.block_size)\n","    else:\n","        return TextDataset(tokenizer=tokenizer, file_path=file_path, block_size=args.block_size, overwrite_cache=args.overwrite_cache)\n"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"4iwQbr1U9YbE"},"source":["## Finetunes GPT-2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"AXE6Zq8-hikF","executionInfo":{"status":"ok","timestamp":1627389548540,"user_tz":420,"elapsed":910,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"1b5b7009-449f-46f0-bcb4-51452362622d"},"source":["def finetune_model(resume_from_checkpoint=True):\n","\n","    model_args = ModelArguments(model_name_or_path=\"gpt2-medium\", model_type=\"gpt2-medium\")\n","\n","    data_args = DataArguments(\n","        train_data_file=training_text,\n","        eval_data_file=eval_text,\n","        line_by_line=True,\n","        block_size=512,\n","        overwrite_cache=True,\n","    )\n","\n","    training_args = TrainingArguments(\n","        output_dir=checkpoint_dir,\n","        overwrite_output_dir=True,\n","        do_train=True,\n","        do_eval=True,\n","        evaluation_strategy=\"steps\",\n","        logging_steps=100,\n","        per_device_train_batch_size=4,\n","        num_train_epochs=1,\n","        save_total_limit=1,\n","        save_steps=8000,\n","        prediction_loss_only=True,\n","        seed=0,\n","        report_to=\"all\",\n","    )\n","\n","    # Performs sanity checks\n","    if data_args.eval_data_file is None and training_args.do_eval:\n","        raise ValueError(\"Cannot do evaluation without an evaluation data file\")\n","\n","    if (os.path.exists(training_args.output_dir)\n","        and os.listdir(training_args.output_dir)\n","        and training_args.do_train\n","        and not training_args.overwrite_output_dir\n","    ):\n","        raise ValueError(f\"{training_args.output_dir} exists but overwrite_output_dir=False\")\n","\n","    # Sets up logging\n","    logging.basicConfig(\n","        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\n","    )\n","    print()\n","    logger.warning(\n","        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n","        training_args.local_rank,\n","        training_args.device,\n","        training_args.n_gpu,\n","        bool(training_args.local_rank != -1),\n","        training_args.fp16,\n","    )\n","    print()\n","    logger.info(\"Training/evaluation parameters %s\", training_args)\n","\n","    # Sets seed for deterministic training runs\n","    set_seed(training_args.seed)\n","\n","    config = AutoConfig.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir)\n","\n","    model = GPT2LMHeadModel.from_pretrained(\n","        model_args.model_name_or_path,\n","        from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n","        config=config,\n","        cache_dir=model_args.cache_dir,\n","    )\n","\n","    # Adds additional tokens.\n","    tokenizer = AutoTokenizer.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir)\n","    special_tokens_dict = {\n","        \"bos_token\": \"<BOS>\",\n","        \"eos_token\": \"<EOS>\",\n","        \"pad_token\": \"<PAD>\",\n","        \"additional_special_tokens\": [\n","            \"<HINT>\",\n","            \"<SENT>\",\n","        ],\n","    }\n","    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n","    model.resize_token_embeddings(len(tokenizer))\n","\n","    # Adjusts the block size.\n","    data_args.block_size = tokenizer.model_max_length if data_args.block_size <= 0 else  min(data_args.block_size, tokenizer.model_max_length)\n","\n","    # Gets the datasets.\n","    train_dataset = (get_dataset(data_args, tokenizer=tokenizer) if training_args.do_train else None)\n","    eval_dataset = (get_dataset(data_args, tokenizer=tokenizer, evaluate=True) if training_args.do_eval else None)\n","    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=data_args.mlm,)\n","\n","    # Initializes the trainer.\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        data_collator=data_collator,\n","        train_dataset=train_dataset,\n","        eval_dataset=eval_dataset,\n","    )\n","\n","    # Performs training.\n","    train_result = {}\n","    try:\n","      if training_args.do_train:\n","          model_path = (\n","              model_args.model_name_or_path\n","              if model_args.model_name_or_path is not None\n","              and os.path.isdir(model_args.model_name_or_path)\n","              else None\n","          )\n","          train_result = trainer.train(resume_from_checkpoint=True if resume_from_checkpoint else model_path)\n","          trainer.save_model()\n","          tokenizer.save_pretrained(training_args.output_dir)\n","    except KeyboardInterrupt:\n","      print(\"Saving model that was in the middle of training\")\n","      trainer.save_model()\n","      tokenizer.save_pretrained(training_args.output_dir)\n","      return\n","\n","    # Performs evaluation.\n","    results = {}\n","    if training_args.do_eval:\n","        logger.info(\"*** Evaluate ***\")\n","\n","        eval_output = trainer.evaluate()\n","        result = { \"perplexity\": math.exp(eval_output[\"eval_loss\"]) }\n","\n","        output_eval_file = os.path.join(training_args.output_dir, \"eval_results_lm.txt\")\n","        if trainer.is_world_process_zero():\n","            with open(output_eval_file, \"w\") as writer:\n","                logger.info(\"***** Eval results *****\")\n","                for key in sorted(result.keys()):\n","                    logger.info(\"  %s = %s\", key, str(result[key]))\n","                    writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n","\n","        results.update(result)\n","\n","    results[\"training_result\"] = train_result\n","    return results\n"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a837de954ca745d68b4711b44c1d55eb","8a056db9ec134ae8a8d4d76b20220137","cb8c48698f384431b5745948d106d76e","9fd1d99781324138af0b7c96b1a2da9c","fbb7a0343f254f5d92a67e7e64939f6f","bcd1cee7f448481e9c095a15dbaba237","73f6a55522384c2f81e535405837124e","5640b2aa60fc4daeb790bcf1998d31ab","cf1e9cfecd114e108498f8597dc9dce8","551de46a771547048c691af99e79fcb6","75cf429061164333b1fe83449d5d8e96","6f645f614d66431ba3675fcce4d9f840","98347625b4244e9fb384c062c9d9849d","5765f42af09c47e79b3eb31b38722e94","53f5133c1a7146daa804849ba98548c4","dc4daf36d2e440928aa62565925e391f","249c875948884376a33718de5c0e6edd","a0a4cb0ff534436bbb40243727be77ab","1f216e975f574e7eb03059c46eb20f67","5ab199eb99ae488e9edcc8d17dc97d6f","ed06efaf35164f93baa14a388a10403f","73027f6a8a9942c7ac77e8f32ebc0946","441db225c62a4ddcb6c0d8ebd4f83ee9","e4cb4eed883643a9965604fef1f0f8a9","fea1fd9bfb31430faa1242b385b7ee71","67ac31fb4cb94ca193d47b7bcb23fd91","a26869b455a54a3b954bb0486fd76c6a","315e9c8ad7bc49a087bf453e80e2cd02","53d4b908efff4d468399a66017fcbd02","c8bdc2d32a814541a1a4671a1e1d7e5a","cfca8bfe639d4698ac844b235eb8ff2e","d06e9feeec5d4965b5eb27744718e2e4","08759b250e1749d1b2d318c90f4f373a","8b3faac218444ce1b7b984136bac1cc6","4d3be4a241fc48c792a2384237c08d1e","745c609a35f347d188b7c516e78959b5","4ba8fc9b18c448f7b81fe1cb4698b84d","4eef64ae2c884c89a947a2287ab7b365","81993161284544fa84771d9258d04a11","95ccc7e1409b46ec9cf301b5967f4da9"]},"id":"RdzdlR4ciaZ6","executionInfo":{"status":"ok","timestamp":1627396961502,"user_tz":420,"elapsed":7406377,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"9c603b41-9d73-4eaa-a44a-854eaa9ae36b"},"source":["finetune_results = finetune_model(resume_from_checkpoint=False)\n"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["07/27/2021 12:39:14 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n","07/27/2021 12:39:14 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_steps=100,\n","evaluation_strategy=IntervalStrategy.STEPS,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","gradient_accumulation_steps=1,\n","greater_is_better=None,\n","group_by_length=False,\n","ignore_data_skip=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=-1,\n","log_level_replica=-1,\n","log_on_each_node=True,\n","logging_dir=/content/drive/MyDrive/W266 Final Project/CnF/PhotoStoryGenerator/GPT-2M-FineTune3_checkpoint/runs/Jul27_12-39-14_66df8a94358c,\n","logging_first_step=False,\n","logging_steps=100,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=1,\n","output_dir=/content/drive/MyDrive/W266 Final Project/CnF/PhotoStoryGenerator/GPT-2M-FineTune3_checkpoint,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=4,\n","prediction_loss_only=True,\n","push_to_hub=False,\n","push_to_hub_model_id=GPT-2M-FineTune3_checkpoint,\n","push_to_hub_organization=None,\n","push_to_hub_token=None,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=/content/drive/MyDrive/W266 Final Project/CnF/PhotoStoryGenerator/GPT-2M-FineTune3_checkpoint,\n","save_on_each_node=False,\n","save_steps=8000,\n","save_strategy=IntervalStrategy.STEPS,\n","save_total_limit=1,\n","seed=0,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n"],"name":"stderr"},{"output_type":"stream","text":["\n","\n"],"name":"stdout"},{"output_type":"stream","text":["07/27/2021 12:39:15 - INFO - filelock -   Lock 140239682602064 acquired on /root/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff.lock\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a837de954ca745d68b4711b44c1d55eb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=718.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["07/27/2021 12:39:16 - INFO - filelock -   Lock 140239682602064 released on /root/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff.lock\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["07/27/2021 12:39:17 - INFO - filelock -   Lock 140239671291600 acquired on /root/.cache/huggingface/transformers/6249eef5c8c1fcfccf9f36fc2e59301b109ac4036d8ebbee9c2b7f7e47f440bd.2538e2565f9e439a3668b981faf959c8b490b36dd631f3c4cd992519b2dd36f1.lock\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf1e9cfecd114e108498f8597dc9dce8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1520013706.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["07/27/2021 12:41:41 - INFO - filelock -   Lock 140239671291600 released on /root/.cache/huggingface/transformers/6249eef5c8c1fcfccf9f36fc2e59301b109ac4036d8ebbee9c2b7f7e47f440bd.2538e2565f9e439a3668b981faf959c8b490b36dd631f3c4cd992519b2dd36f1.lock\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["07/27/2021 12:41:48 - INFO - filelock -   Lock 140239657881104 acquired on /root/.cache/huggingface/transformers/fee58641d7a73348d842afaa337d5a7763dad32beff8d9008bb3c3c847749d6b.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f.lock\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"249c875948884376a33718de5c0e6edd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["07/27/2021 12:41:49 - INFO - filelock -   Lock 140239657881104 released on /root/.cache/huggingface/transformers/fee58641d7a73348d842afaa337d5a7763dad32beff8d9008bb3c3c847749d6b.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f.lock\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["07/27/2021 12:41:50 - INFO - filelock -   Lock 140239657881168 acquired on /root/.cache/huggingface/transformers/23c853a0fcfc12c7d72ad4e922068b6982665b673f6de30b4c5cbe5bd70a2236.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b.lock\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fea1fd9bfb31430faa1242b385b7ee71","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["07/27/2021 12:41:51 - INFO - filelock -   Lock 140239657881168 released on /root/.cache/huggingface/transformers/23c853a0fcfc12c7d72ad4e922068b6982665b673f6de30b4c5cbe5bd70a2236.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b.lock\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["07/27/2021 12:41:52 - INFO - filelock -   Lock 140239658063952 acquired on /root/.cache/huggingface/transformers/8e4f9a65085b1b4ae69ffac9a953a44249c9ea1e72e4a7816ee87b70081df038.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0.lock\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08759b250e1749d1b2d318c90f4f373a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355256.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["07/27/2021 12:41:54 - INFO - filelock -   Lock 140239658063952 released on /root/.cache/huggingface/transformers/8e4f9a65085b1b4ae69ffac9a953a44249c9ea1e72e4a7816ee87b70081df038.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0.lock\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:124: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 26959\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6740\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6740' max='6740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6740/6740 1:59:06, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>5.906400</td>\n","      <td>3.993014</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>4.034900</td>\n","      <td>3.910951</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>3.944200</td>\n","      <td>3.859285</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>3.896800</td>\n","      <td>3.829963</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>3.811300</td>\n","      <td>3.788842</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>3.836600</td>\n","      <td>3.781228</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>3.801500</td>\n","      <td>3.748664</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>3.797300</td>\n","      <td>3.734863</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>3.737900</td>\n","      <td>3.717789</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>3.751500</td>\n","      <td>3.716526</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>3.706300</td>\n","      <td>3.709018</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>3.701100</td>\n","      <td>3.699522</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>3.711100</td>\n","      <td>3.685198</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>3.674700</td>\n","      <td>3.677271</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>3.641200</td>\n","      <td>3.672000</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>3.662700</td>\n","      <td>3.664619</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>3.630500</td>\n","      <td>3.656575</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>3.631900</td>\n","      <td>3.648107</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>3.671900</td>\n","      <td>3.646186</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>3.597700</td>\n","      <td>3.641433</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>3.636200</td>\n","      <td>3.636772</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>3.592900</td>\n","      <td>3.634875</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>3.623400</td>\n","      <td>3.627289</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>3.575000</td>\n","      <td>3.620356</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>3.570600</td>\n","      <td>3.621752</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>3.566200</td>\n","      <td>3.615182</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>3.573500</td>\n","      <td>3.618455</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>3.546200</td>\n","      <td>3.611249</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>3.559500</td>\n","      <td>3.608036</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>3.572500</td>\n","      <td>3.603832</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>3.525800</td>\n","      <td>3.602709</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>3.542800</td>\n","      <td>3.597339</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>3.530300</td>\n","      <td>3.597111</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>3.509300</td>\n","      <td>3.591509</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>3.524000</td>\n","      <td>3.587424</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>3.526600</td>\n","      <td>3.589585</td>\n","    </tr>\n","    <tr>\n","      <td>3700</td>\n","      <td>3.502300</td>\n","      <td>3.584531</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>3.508300</td>\n","      <td>3.587197</td>\n","    </tr>\n","    <tr>\n","      <td>3900</td>\n","      <td>3.520300</td>\n","      <td>3.581428</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>3.465400</td>\n","      <td>3.580642</td>\n","    </tr>\n","    <tr>\n","      <td>4100</td>\n","      <td>3.504600</td>\n","      <td>3.579669</td>\n","    </tr>\n","    <tr>\n","      <td>4200</td>\n","      <td>3.482400</td>\n","      <td>3.579346</td>\n","    </tr>\n","    <tr>\n","      <td>4300</td>\n","      <td>3.476700</td>\n","      <td>3.573065</td>\n","    </tr>\n","    <tr>\n","      <td>4400</td>\n","      <td>3.461200</td>\n","      <td>3.572864</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>3.464900</td>\n","      <td>3.569785</td>\n","    </tr>\n","    <tr>\n","      <td>4600</td>\n","      <td>3.475300</td>\n","      <td>3.567668</td>\n","    </tr>\n","    <tr>\n","      <td>4700</td>\n","      <td>3.482900</td>\n","      <td>3.565992</td>\n","    </tr>\n","    <tr>\n","      <td>4800</td>\n","      <td>3.457400</td>\n","      <td>3.568228</td>\n","    </tr>\n","    <tr>\n","      <td>4900</td>\n","      <td>3.502600</td>\n","      <td>3.563445</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>3.479900</td>\n","      <td>3.561403</td>\n","    </tr>\n","    <tr>\n","      <td>5100</td>\n","      <td>3.457300</td>\n","      <td>3.560775</td>\n","    </tr>\n","    <tr>\n","      <td>5200</td>\n","      <td>3.449600</td>\n","      <td>3.559860</td>\n","    </tr>\n","    <tr>\n","      <td>5300</td>\n","      <td>3.449900</td>\n","      <td>3.556977</td>\n","    </tr>\n","    <tr>\n","      <td>5400</td>\n","      <td>3.444300</td>\n","      <td>3.556614</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>3.460400</td>\n","      <td>3.555598</td>\n","    </tr>\n","    <tr>\n","      <td>5600</td>\n","      <td>3.477400</td>\n","      <td>3.553065</td>\n","    </tr>\n","    <tr>\n","      <td>5700</td>\n","      <td>3.478000</td>\n","      <td>3.552858</td>\n","    </tr>\n","    <tr>\n","      <td>5800</td>\n","      <td>3.475800</td>\n","      <td>3.553587</td>\n","    </tr>\n","    <tr>\n","      <td>5900</td>\n","      <td>3.444200</td>\n","      <td>3.553007</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>3.428800</td>\n","      <td>3.550254</td>\n","    </tr>\n","    <tr>\n","      <td>6100</td>\n","      <td>3.413100</td>\n","      <td>3.550101</td>\n","    </tr>\n","    <tr>\n","      <td>6200</td>\n","      <td>3.470400</td>\n","      <td>3.548993</td>\n","    </tr>\n","    <tr>\n","      <td>6300</td>\n","      <td>3.475000</td>\n","      <td>3.548971</td>\n","    </tr>\n","    <tr>\n","      <td>6400</td>\n","      <td>3.445500</td>\n","      <td>3.547753</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>3.459000</td>\n","      <td>3.547809</td>\n","    </tr>\n","    <tr>\n","      <td>6600</td>\n","      <td>3.434900</td>\n","      <td>3.547754</td>\n","    </tr>\n","    <tr>\n","      <td>6700</td>\n","      <td>3.433100</td>\n","      <td>3.547626</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Saving model checkpoint to /content/drive/MyDrive/W266 Final Project/CnF/PhotoStoryGenerator/GPT-2M-FineTune3_checkpoint\n","Configuration saved in /content/drive/MyDrive/W266 Final Project/CnF/PhotoStoryGenerator/GPT-2M-FineTune3_checkpoint/config.json\n","Model weights saved in /content/drive/MyDrive/W266 Final Project/CnF/PhotoStoryGenerator/GPT-2M-FineTune3_checkpoint/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/W266 Final Project/CnF/PhotoStoryGenerator/GPT-2M-FineTune3_checkpoint/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/W266 Final Project/CnF/PhotoStoryGenerator/GPT-2M-FineTune3_checkpoint/special_tokens_map.json\n","07/27/2021 14:41:27 - INFO - __main__ -   *** Evaluate ***\n","***** Running Evaluation *****\n","  Num examples = 3354\n","  Batch size = 8\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [420/420 01:13]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["07/27/2021 14:42:40 - INFO - __main__ -   ***** Eval results *****\n","07/27/2021 14:42:40 - INFO - __main__ -     perplexity = 34.7291546871324\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"6PuD8DwWX6XS","executionInfo":{"status":"ok","timestamp":1627396961503,"user_tz":420,"elapsed":33,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"09140941380350255048"}},"outputId":"a053cb08-00a7-46d9-db87-b132d763462c"},"source":["finetune_results\n"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'perplexity': 34.7291546871324,\n"," 'training_result': TrainOutput(global_step=6740, training_loss=3.6050194646908906, metrics={'train_runtime': 7147.3443, 'train_samples_per_second': 3.772, 'train_steps_per_second': 0.943, 'total_flos': 7353838453272576.0, 'train_loss': 3.6050194646908906, 'epoch': 1.0})}"]},"metadata":{"tags":[]},"execution_count":15}]}]}